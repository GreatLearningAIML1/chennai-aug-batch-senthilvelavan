{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sb7Epo0VOB58"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHpCNRv1OB5-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnSsH8sNOB6F",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Reset Default graph - Needed only for Jupyter notebook\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxJDmJqqOB6K",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhllFLyKOB6N"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24396,
     "status": "ok",
     "timestamp": 1547988227655,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "ExeOoigeao03",
    "outputId": "4db47687-218d-4598-fca4-1775c630ebbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25116,
     "status": "ok",
     "timestamp": 1547988228395,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "B4yQKMiJOB6R",
    "outputId": "7cce917b-5b03-4334-bd02-d0d873bc3dce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date symbol        open       close         low        high  \\\n",
       "0  2016-01-05 00:00:00   WLTW  123.430000  125.839996  122.309998  126.250000   \n",
       "1  2016-01-06 00:00:00   WLTW  125.239998  119.980003  119.940002  125.540001   \n",
       "2  2016-01-07 00:00:00   WLTW  116.379997  114.949997  114.930000  119.739998   \n",
       "3  2016-01-08 00:00:00   WLTW  115.480003  116.620003  113.500000  117.440002   \n",
       "4  2016-01-11 00:00:00   WLTW  117.010002  114.970001  114.089996  117.330002   \n",
       "\n",
       "      volume  \n",
       "0  2163600.0  \n",
       "1  2386400.0  \n",
       "2  2489500.0  \n",
       "3  2006300.0  \n",
       "4  1408600.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/content/gdrive/My Drive/AIML/Labs/R6-Internal/prices.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgkX6SEqOB6W"
   },
   "source": [
    "### Check all columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25094,
     "status": "ok",
     "timestamp": 1547988228398,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "7K8pWsNQOB6X",
    "outputId": "a21102c8-d2f9-4777-8221-965f9cb495d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 851264 entries, 0 to 851263\n",
      "Data columns (total 7 columns):\n",
      "date      851264 non-null object\n",
      "symbol    851264 non-null object\n",
      "open      851264 non-null float64\n",
      "close     851264 non-null float64\n",
      "low       851264 non-null float64\n",
      "high      851264 non-null float64\n",
      "volume    851264 non-null float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dU6X7MpOB6c"
   },
   "source": [
    "### Drop columns `date` and  `symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lh_6spSKOB6e"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=['date','symbol'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25068,
     "status": "ok",
     "timestamp": 1547988228405,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "xlwbUgTwOB6i",
    "outputId": "45300997-a098-414d-d873-0d266a989d3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high     volume\n",
       "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DBv3WWYOB6q"
   },
   "source": [
    "### Consider only first 1000 rows in the dataset for building feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25374,
     "status": "ok",
     "timestamp": 1547988228724,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "Z_hG9rGBOB6s",
    "outputId": "918f9cae-2c0e-4411-849c-8bff534fcba4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1000 = data.head(1000)\n",
    "data1000.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3UaApqYOB6x"
   },
   "source": [
    "### Divide the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25365,
     "status": "ok",
     "timestamp": 1547988228726,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "2EkKAy7fOB6y",
    "outputId": "f0a771f8-2e53-4a30-db7c-5903d8e3b76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data1000.copy(deep=True)\n",
    "Y = data1000['close']\n",
    "X.drop(columns='close', inplace=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25354,
     "status": "ok",
     "timestamp": 1547988228740,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "lr1rAsNEeox9",
    "outputId": "dfa52ba0-0ab6-4dd7-bf0b-e09647215f33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open         low        high     volume\n",
       "0  123.430000  122.309998  126.250000  2163600.0\n",
       "1  125.239998  119.940002  125.540001  2386400.0\n",
       "2  116.379997  114.930000  119.739998  2489500.0\n",
       "3  115.480003  113.500000  117.440002  2006300.0\n",
       "4  117.010002  114.089996  117.330002  1408600.0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25342,
     "status": "ok",
     "timestamp": 1547988228740,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "PwR4eFExerFU",
    "outputId": "74e3727e-bf1b-4ef9-8d3d-3f6ab2a9322f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    125.839996\n",
       "1    119.980003\n",
       "2    114.949997\n",
       "3    116.620003\n",
       "4    114.970001\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6vE4eYCOB62",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the graph in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xK0zBd1VOB64",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1.Define input data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDrYlWTuOB66"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None,4], name='x-input')\n",
    "x_n = tf.layers.batch_normalization(x,training=True)\n",
    "y_ = tf.placeholder(dtype=tf.float32, shape=[None], name='y-input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "297_qja4OB7A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.Define Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L205qPeQOB7B"
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros(shape=[4,1]), dtype=tf.float32, name=\"Weights\")\n",
    "b = tf.Variable(tf.zeros(shape=[1]), name=\"Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgtWA-UIOB7F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JveGlx25OB7H"
   },
   "outputs": [],
   "source": [
    "y = tf.add(tf.matmul(x_n, W), b, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL1hIwf_OB7M",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4.Loss (Cost) Function [Mean square error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VSWPiGXOB7P"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y-y_), name='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzG85FUlOB7U",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cj802w-3OB7X"
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.03).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSypb_u8OB7e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execute the Graph for 100 epochs and observe the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVvgj7eQOB7f"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27314,
     "status": "ok",
     "timestamp": 1547988230798,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "9smwOW-1OB7k",
    "outputId": "a55c9bd7-cbd7-41b7-9d44-9fec91c68a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training loss at step: ', 0, ' is ', 8370.378)\n",
      "('Training loss at step: ', 10, ' is ', 4992.165)\n",
      "('Training loss at step: ', 20, ' is ', 3689.0046)\n",
      "('Training loss at step: ', 30, ' is ', 4038.9663)\n",
      "('Training loss at step: ', 40, ' is ', 4018.743)\n",
      "('Training loss at step: ', 50, ' is ', 3747.9004)\n",
      "('Training loss at step: ', 60, ' is ', 3711.2063)\n",
      "('Training loss at step: ', 70, ' is ', 3708.5874)\n",
      "('Training loss at step: ', 80, ' is ', 3701.5264)\n",
      "('Training loss at step: ', 90, ' is ', 3696.081)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "  \n",
    "  _, train_loss = sess.run([train_op,loss], feed_dict={x:X_train,\n",
    "                                                       y_:Y_train})\n",
    "  \n",
    "  if epoch % 10 == 0:\n",
    "     print ('Training loss at step: ', epoch, ' is ', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27304,
     "status": "ok",
     "timestamp": 1547988230799,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "9JuLI6bSOB7n",
    "outputId": "2bdf42e5-abee-4fd5-9e43-a4fc14ac91ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3702.1038"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOL2ncA1OB7q"
   },
   "source": [
    "### Get the shapes and values of W and b\n",
    "\n",
    "Hint: Use sess.run(W) to get W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27293,
     "status": "ok",
     "timestamp": 1547988230800,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "ZGvtyTeuOB7r",
    "outputId": "589b7c93-53bd-410b-8333-dba4b23c1402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8714082 ],\n",
       "       [ 0.8775928 ],\n",
       "       [-3.4261193 ],\n",
       "       [ 0.02576405]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27282,
     "status": "ok",
     "timestamp": 1547988230800,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "vhDtOv5UOB7x",
    "outputId": "e14121ab-6011-4a4c-8017-3f356cb1a680"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.513824], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZqKUEFsOB71"
   },
   "source": [
    "### Find the Absolute mean square loss difference between training and testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97t-grQgOB71"
   },
   "outputs": [],
   "source": [
    "Y_pred = sess.run(y, feed_dict={x:X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27262,
     "status": "ok",
     "timestamp": 1547988230802,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "_9Jhj2UgxNUW",
    "outputId": "27864a32-77ab-4834-fc3e-6c656f4ee96b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27250,
     "status": "ok",
     "timestamp": 1547988230803,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "9S-FW-AzxtsA",
    "outputId": "8d32627c-47ca-401a-e461-43ce9ee01e00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2828.6741618732212"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_loss = mean_squared_error(Y_test,Y_pred)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIgi2TgB4wuJ"
   },
   "outputs": [],
   "source": [
    "##tf.reduce_mean(tf.square(Y_test-Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1547988275178,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "lCh1BtFe0LZq",
    "outputId": "f27ab349-c29a-47f5-9d91-107d63cd44cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873.4295978924038"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = train_loss - test_loss\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1547988276346,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "1VTNHMle1w_1",
    "outputId": "f4acfd87-76fb-4398-c248-648adfb7bd24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for epoch in range(training_epochs):\\n  \\n  _, test_loss_1 = sess.run([train_op,loss], feed_dict={x:X_test,\\n                                                       y_:Y_test})\\n  \\n  if epoch % 10 == 0:\\n     print ('Test loss at step: ', epoch, ' is ', test_loss_1)\""
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for epoch in range(training_epochs):\n",
    "  \n",
    "  _, test_loss_1 = sess.run([train_op,loss], feed_dict={x:X_test,\n",
    "                                                       y_:Y_test})\n",
    "  \n",
    "  if epoch % 10 == 0:\n",
    "     print ('Test loss at step: ', epoch, ' is ', test_loss_1)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrcNYYX-1ZwK"
   },
   "source": [
    "<h4> The difference between training and testing loss is 896.71 <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJRBuqXhOB7_"
   },
   "source": [
    "### Linear Classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GoNTWXAOB8C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
    "#### Use Mean square error as loss function and sgd as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpeL5rCTOB8D"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential Graph (model)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Normalize input data\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(4,)))\n",
    "\n",
    "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
    "model.add(tf.keras.layers.Dense(1, input_shape=(4,)))\n",
    "\n",
    "#Compile the model - add Loss and Gradient Descent optimizer\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt-HYFMEOB8G",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3554
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3523,
     "status": "ok",
     "timestamp": 1547988288909,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "66JGJt7GOB8H",
    "outputId": "ef15112e-91b1-47a7-e8aa-ff88e6b30f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "700/700 [==============================] - 0s 215us/step - loss: nan\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: nan\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s 30us/step - loss: nan\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s 35us/step - loss: nan\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s 30us/step - loss: nan\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s 35us/step - loss: nan\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s 39us/step - loss: nan\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s 35us/step - loss: nan\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: nan\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: nan\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s 39us/step - loss: nan\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: nan\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s 40us/step - loss: nan\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: nan\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: nan\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: nan\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s 44us/step - loss: nan\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: nan\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s 41us/step - loss: nan\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s 39us/step - loss: nan\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s 35us/step - loss: nan\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: nan\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: nan\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: nan\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s 35us/step - loss: nan\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s 30us/step - loss: nan\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: nan\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s 37us/step - loss: nan\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s 38us/step - loss: nan\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: nan\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s 36us/step - loss: nan\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s 34us/step - loss: nan\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s 31us/step - loss: nan\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s 32us/step - loss: nan\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s 33us/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff114c192d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1547988293471,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "OkxhWJPdHfZ4",
    "outputId": "385f17f8-043a-4c0d-8dae-a0d8d1445242"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1547988294755,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "dsw3n6O6Hi1K",
    "outputId": "6ae65ec7-9b20-4e9b-f99c-c678b02409b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxfKYWM3Zo4p"
   },
   "source": [
    "### Classification using Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nuRt5tWOZo4t"
   },
   "source": [
    "### Load the given Iris data using pandas (Iris.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1547988298990,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "upbMSOucZo4v",
    "outputId": "e29143e2-79af-49d5-db31-c8cc471a85d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.read_csv('/content/gdrive/My Drive/AIML/Labs/R6-Internal/Iris.csv')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1040,
     "status": "ok",
     "timestamp": 1547988301419,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "61NW1i2mKW0n",
    "outputId": "183a1ddd-3474-4073-9157-1085bc4d01b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      "Id               150 non-null int64\n",
      "SepalLengthCm    150 non-null float64\n",
      "SepalWidthCm     150 non-null float64\n",
      "PetalLengthCm    150 non-null float64\n",
      "PetalWidthCm     150 non-null float64\n",
      "Species          150 non-null object\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.1+ KB\n"
     ]
    }
   ],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTsYOlJ8LCnB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJSenOpXZo4w"
   },
   "source": [
    "### Splitting the data into feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qKG7_1EZo4z"
   },
   "outputs": [],
   "source": [
    "X_iris = iris_df.copy(deep=True)\n",
    "Y_iris = X_iris['Species']\n",
    "X_iris.drop(columns=['Species','Id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1547988336647,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "B3N6TT0qR3bN",
    "outputId": "6483ebba-b9f3-48c6-825c-7a8fe6e6cf19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1THS_ObRZo41"
   },
   "source": [
    "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1882
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1547988341382,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "40Av2S79Zo43",
    "outputId": "aac86f06-3bd2-4627-a3b6-ad1a1c1a0d5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0              1                0               0\n",
       "1              1                0               0\n",
       "2              1                0               0\n",
       "3              1                0               0\n",
       "4              1                0               0\n",
       "5              1                0               0\n",
       "6              1                0               0\n",
       "7              1                0               0\n",
       "8              1                0               0\n",
       "9              1                0               0\n",
       "10             1                0               0\n",
       "11             1                0               0\n",
       "12             1                0               0\n",
       "13             1                0               0\n",
       "14             1                0               0\n",
       "15             1                0               0\n",
       "16             1                0               0\n",
       "17             1                0               0\n",
       "18             1                0               0\n",
       "19             1                0               0\n",
       "20             1                0               0\n",
       "21             1                0               0\n",
       "22             1                0               0\n",
       "23             1                0               0\n",
       "24             1                0               0\n",
       "25             1                0               0\n",
       "26             1                0               0\n",
       "27             1                0               0\n",
       "28             1                0               0\n",
       "29             1                0               0\n",
       "..           ...              ...             ...\n",
       "120            0                0               1\n",
       "121            0                0               1\n",
       "122            0                0               1\n",
       "123            0                0               1\n",
       "124            0                0               1\n",
       "125            0                0               1\n",
       "126            0                0               1\n",
       "127            0                0               1\n",
       "128            0                0               1\n",
       "129            0                0               1\n",
       "130            0                0               1\n",
       "131            0                0               1\n",
       "132            0                0               1\n",
       "133            0                0               1\n",
       "134            0                0               1\n",
       "135            0                0               1\n",
       "136            0                0               1\n",
       "137            0                0               1\n",
       "138            0                0               1\n",
       "139            0                0               1\n",
       "140            0                0               1\n",
       "141            0                0               1\n",
       "142            0                0               1\n",
       "143            0                0               1\n",
       "144            0                0               1\n",
       "145            0                0               1\n",
       "146            0                0               1\n",
       "147            0                0               1\n",
       "148            0                0               1\n",
       "149            0                0               1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y_iris = pd.DataFrame(le.fit_transform(Y_iris))'''\n",
    "\n",
    "Y_iris = pd.get_dummies(Y_iris)\n",
    "Y_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1547988343514,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "hiMvswryRu1L",
    "outputId": "a465464e-f711-4a90-e1b0-583d3b391402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JX93toMQZo44"
   },
   "source": [
    "### Divide the dataset into Training and test (70:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHyyiPlRZo45"
   },
   "outputs": [],
   "source": [
    "X_iris_train,X_iris_test,Y_iris_train,Y_iris_test = train_test_split(X_iris,Y_iris,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1547988350577,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "1A1AStMWMi7A",
    "outputId": "f887ce00-f818-4618-9abc-115306884ad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1379
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1547988353618,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "AWV6VAj7PSD8",
    "outputId": "e7fc301e-0c5e-4c28-ba40-3f40786eceb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "149            0                0               1\n",
       "84             0                1               0\n",
       "40             1                0               0\n",
       "66             0                1               0\n",
       "106            0                0               1\n",
       "41             1                0               0\n",
       "52             0                1               0\n",
       "94             0                1               0\n",
       "11             1                0               0\n",
       "51             0                1               0\n",
       "77             0                1               0\n",
       "85             0                1               0\n",
       "32             1                0               0\n",
       "109            0                0               1\n",
       "28             1                0               0\n",
       "70             0                1               0\n",
       "108            0                0               1\n",
       "137            0                0               1\n",
       "46             1                0               0\n",
       "37             1                0               0\n",
       "82             0                1               0\n",
       "120            0                0               1\n",
       "63             0                1               0\n",
       "119            0                0               1\n",
       "129            0                0               1\n",
       "138            0                0               1\n",
       "97             0                1               0\n",
       "80             0                1               0\n",
       "101            0                0               1\n",
       "140            0                0               1\n",
       "126            0                0               1\n",
       "79             0                1               0\n",
       "22             1                0               0\n",
       "139            0                0               1\n",
       "74             0                1               0\n",
       "45             1                0               0\n",
       "36             1                0               0\n",
       "5              1                0               0\n",
       "17             1                0               0\n",
       "102            0                0               1\n",
       "124            0                0               1\n",
       "76             0                1               0\n",
       "132            0                0               1\n",
       "116            0                0               1\n",
       "95             0                1               0"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_iris_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qub1gs_TZo47"
   },
   "source": [
    "### Model\n",
    "Build the model with following layers: <br>\n",
    "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
    "2. Second Dense layer with 8 neurons <br>\n",
    "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
    "4. Use SGD and categorical_crossentropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaNlpl0SZo48"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf1\n",
    "\n",
    "tf1.reset_default_graph()\n",
    "tf1.set_random_seed(42)\n",
    "\n",
    "#Initialize Sequential model\n",
    "model_iris = tf1.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "##model_iris.add(tf.keras.layers.Reshape((4,),))\n",
    "\n",
    "\n",
    "model_iris.add(tf.keras.layers.Dense(3))\n",
    "#Normalize the data\n",
    "model_iris.add(tf.keras.layers.BatchNormalization(input_shape=(4,)))\n",
    "\n",
    "\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
    "model_iris.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "model_iris.add(tf.keras.layers.Dense(8, activation='sigmoid'))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model_iris.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "#Comile the model\n",
    "model_iris.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1547989692003,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "c7hXRxzzX7ir",
    "outputId": "f07748a3-61cd-4f1e-ee3a-94f8f4f140a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 13\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_CHEKA4Zo49"
   },
   "source": [
    "### Fitting the model and predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1701
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797,
     "status": "error",
     "timestamp": 1547989706311,
     "user": {
      "displayName": "chenthur murugan",
      "photoUrl": "",
      "userId": "10011307527226996772"
     },
     "user_tz": -330
    },
    "id": "ln5U8mOqZo4-",
    "outputId": "c67f8405-6fd7-44df-d125-fb39c37359cd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-fe7694db5f25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_iris.fit(X_iris_train,Y_iris_train,          \n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_iris_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_iris_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=30)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m           raise ValueError('Please provide as model inputs either a single '\n\u001b[0;32m-> 1024\u001b[0;31m                            'array or a list of arrays. You passed: x=' + str(x))\n\u001b[0m\u001b[1;32m   1025\u001b[0m         \u001b[0mall_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: x=     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n49             5.0           3.3            1.4           0.2\n65             6.7           3.1            4.4           1.4\n62             6.0           2.2            4.0           1.0\n111            6.4           2.7            5.3           1.9\n29             4.7           3.2            1.6           0.2\n3              4.6           3.1            1.5           0.2\n39             5.1           3.4            1.5           0.2\n117            7.7           3.8            6.7           2.2\n13             4.3           3.0            1.1           0.1\n100            6.3           3.3            6.0           2.5\n81             5.5           2.4            3.7           1.0\n60             5.0           2.0            3.5           1.0\n54             6.5           2.8            4.6           1.5\n26             5.0           3.4            1.6           0.4\n8              4.4           2.9            1.4           0.2\n43             5.0           3.5            1.6           0.6\n86             6.7           3.1            4.7           1.5\n107            7.3           2.9            6.3           1.8\n90             5.5           2.6            4.4           1.2\n59             5.2           2.7            3.9           1.4\n15             5.7           4.4            1.5           0.4\n125            7.2           3.2            6.0           1.8\n20             5.4           3.4            1.7           0.2\n14             5.8           4.0            1.2           0.2\n134            6.1           2.6            5.6           1.4\n113            5.7           2.5            5.0           2.0\n12             4.8           3.0            1.4           0.1\n104            6.5           3.0            5.8           2.2\n47             4.6           3.2            1.4           0.2\n58             6.6           2.9            4.6           1.3\n..             ...           ...            ...           ...\n34             4.9           3.1            1.5           0.1\n64             5.6           2.9            3.6           1.3\n61             5.9           3.0            4.2           1.5\n123            6.3           2.7            4.9           1.8\n112            6.8           3.0            5.5           2.1\n53             5.5           2.3            4.0           1.3\n133            6.3           2.8            5.1           1.5\n24             4.8           3.4            1.9           0.2\n56             6.3           3.3            4.7           1.6\n69             5.6           2.5            3.9           1.1\n44             5.1           3.8            1.9           0.4\n19             5.1           3.8            1.5           0.3\n6              4.6           3.4            1.4           0.3\n55             5.7           2.8            4.5           1.3\n75             6.6           3.0            4.4           1.4\n0              5.1           3.5            1.4           0.2\n135            7.7           3.0            6.1           2.3\n127            6.1           3.0            4.9           1.8\n68             6.2           2.2            4.5           1.5\n136            6.3           3.4            5.6           2.4\n42             4.4           3.2            1.3           0.2\n110            6.5           3.2            5.1           2.0\n89             5.5           2.5            4.0           1.3\n72             6.3           2.5            4.9           1.5\n23             5.1           3.3            1.7           0.5\n142            5.8           2.7            5.1           1.9\n92             5.8           2.6            4.0           1.2\n103            6.3           2.9            5.6           1.8\n67             5.8           2.7            4.1           1.0\n25             5.0           3.0            1.6           0.2\n\n[105 rows x 4 columns]"
     ]
    }
   ],
   "source": [
    "model_iris.fit(X_iris_train,Y_iris_train,          \n",
    "          validation_data=(X_iris_test,Y_iris_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrAPbRmEZo5A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPE4zoRsZo5B"
   },
   "source": [
    "### Report Accuracy of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1OUdx1dZo5D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YJRBuqXhOB7_",
    "lPE4zoRsZo5B"
   ],
   "name": "R6_InternalLab_AIML.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R7_ExternalLab_Questions.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"4WH1Pr4KQlCh","colab_type":"text"},"cell_type":"markdown","source":["### Build a DNN using Keras with `RELU` and `ADAM`"]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"TbvI8LqlQlCl","colab_type":"text"},"cell_type":"markdown","source":["#### Load tensorflow"]},{"metadata":{"id":"SPW-a-qYQlCp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"870c3562-65d8-4743-8847-1d505c214e4a","executionInfo":{"status":"ok","timestamp":1551021427625,"user_tz":-330,"elapsed":1709,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["import tensorflow as tf\n","import keras\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"74cQBsi5QlCw","colab_type":"text"},"cell_type":"markdown","source":["#### Collect Fashion mnist data from tf.keras.datasets "]},{"metadata":{"id":"8H4gOaeJQlCx","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import fashion_mnist"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"no7aWYZyQlC1","colab_type":"text"},"cell_type":"markdown","source":["#### Change train and test labels into one-hot vectors"]},{"metadata":{"id":"UX6otc4wQlC2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"outputId":"dc3bf5a7-c44d-4200-ae63-0b3f9bfb9db6","executionInfo":{"status":"ok","timestamp":1551021447359,"user_tz":-330,"elapsed":6110,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 5us/step\n","40960/29515 [=========================================] - 0s 4us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 2s 0us/step\n","26435584/26421880 [==============================] - 2s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 1s 0us/step\n","4431872/4422102 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"aLwZKrR0D9o9","colab_type":"code","outputId":"34093e55-1b72-481c-a717-1c58e5ac3896","executionInfo":{"status":"ok","timestamp":1551021447892,"user_tz":-330,"elapsed":3759,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_train.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"i5XLw9v_J7OH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1495},"outputId":"0ef4ac16-1f04-4b71-e5d4-3f734ed40987","executionInfo":{"status":"ok","timestamp":1551022672074,"user_tz":-330,"elapsed":861,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["x_train[0]"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n","          1,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n","          0,   3],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n","          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n","         72,  15],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n","         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n","        172,  66],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n","        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n","        229,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n","        173,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n","        202,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n","        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n","        209,  52],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n","        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n","        167,  56],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n","        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n","         92,   0],\n","       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n","        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n","         77,   0],\n","       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n","        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n","        159,   0],\n","       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n","        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n","        215,   0],\n","       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n","        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n","        246,   0],\n","       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n","         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n","        225,   0],\n","       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n","        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n","        229,  29],\n","       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n","        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n","        230,  67],\n","       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n","        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n","        206, 115],\n","       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n","        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n","        210,  92],\n","       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n","        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n","        170,   0],\n","       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n","        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"gTnWCM5HD_xp","colab_type":"code","outputId":"a9c7ab93-d5ce-43dd-f113-e3f25bcf845d","executionInfo":{"status":"ok","timestamp":1551021447894,"user_tz":-330,"elapsed":2008,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x_test.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"F4vpYD_MEBlB","colab_type":"code","outputId":"7f61b1c9-802d-4564-e888-0bb5e92d8fe3","executionInfo":{"status":"ok","timestamp":1551021447895,"user_tz":-330,"elapsed":1168,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["y_train.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000,)"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"ODAczz92EGIZ","colab_type":"code","outputId":"6f94c068-5dca-47d9-f0d6-8fa6ac94e7c3","executionInfo":{"status":"ok","timestamp":1551021447902,"user_tz":-330,"elapsed":550,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["y_test.shape"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000,)"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"bQGnfPiGFFVX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c2a033c4-96b7-4760-e2f6-601381f75fb0","executionInfo":{"status":"ok","timestamp":1551021916935,"user_tz":-330,"elapsed":837,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","print(pd.Series(y_train).value_counts().index)\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["UInt64Index([9, 8, 7, 6, 5, 4, 3, 2, 1, 0], dtype='uint64')\n"],"name":"stdout"}]},{"metadata":{"id":"knNZPSw0Kl_o","colab_type":"code","colab":{}},"cell_type":"code","source":["Y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n","Y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7tT5gzHZKvR9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"da36adc5-631f-45f1-ed40-47adb03b5bef","executionInfo":{"status":"ok","timestamp":1551022885023,"user_tz":-330,"elapsed":1032,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["Y_train.shape"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 10)"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"vGkdG2oyKxN9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8c0f79a2-e9b5-44e6-e04a-ed1ad51a4dde","executionInfo":{"status":"ok","timestamp":1551022892628,"user_tz":-330,"elapsed":831,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["Y_test.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 10)"]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"OhZQBKdBK1cb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f92584c9-8895-4f91-8a8f-8b2281af6bbb","executionInfo":{"status":"ok","timestamp":1551022909765,"user_tz":-330,"elapsed":838,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["Y_train[0]"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"cLnmxX6hK58v","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = x_train/255\n","X_test = x_test/255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j0NJi3QHLALu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1002},"outputId":"f2749bda-4063-4852-b9fe-3a1f2463b23d","executionInfo":{"status":"ok","timestamp":1551023171841,"user_tz":-330,"elapsed":820,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["X_test[0]"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0]], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"_8zNoaR6L9Lj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7e47f50c-b2bd-4af1-ecd5-2b08283abb0a","executionInfo":{"status":"ok","timestamp":1551023203382,"user_tz":-330,"elapsed":851,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["X_train.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":39}]},{"metadata":{"id":"FFy1sAGiL_0y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"36734171-4985-4aee-f694-afc9063017fb","executionInfo":{"status":"ok","timestamp":1551023213968,"user_tz":-330,"elapsed":1029,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["X_test.shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"QjNrRTdoQlC5","colab_type":"text"},"cell_type":"markdown","source":["#### Build the Graph"]},{"metadata":{"id":"bJlEl46yL73Q","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"CDJ9DHVNQlC7","colab_type":"text"},"cell_type":"markdown","source":["#### Initialize model, reshape & normalize data"]},{"metadata":{"id":"pCDQs_g1QlC8","colab_type":"code","colab":{}},"cell_type":"code","source":["#Initialize Sequential model\n","model = tf.keras.models.Sequential()\n","\n","#Reshape data from 2D to 1D -> 28x28 to 784\n","model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","#Normalize the data\n","model.add(tf.keras.layers.BatchNormalization())\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"id":"kBGwTTilQlDD","colab_type":"text"},"cell_type":"markdown","source":["#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"]},{"metadata":{"id":"IXbfpfOzQlDF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fully Connected Layer\n","model.add(tf.keras.layers.Dense(200))\n","model.add(tf.keras.layers.Activation('relu'))\n","\n","# Fully Connected Layer\n","model.add(tf.keras.layers.Dense(100))\n","model.add(tf.keras.layers.Activation('relu'))\n","\n","# Dropout\n","model.add(tf.keras.layers.Dropout(0.25))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5I8f5otcQlDJ","colab_type":"text"},"cell_type":"markdown","source":["### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."]},{"metadata":{"id":"E25kuP_NQlDM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Prediction Layer\n","model.add(tf.keras.layers.Dense(10))\n","model.add(tf.keras.layers.Activation('softmax'))\n","\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.3)\n","\n","#Comile the model\n","model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zV7yyClzTtmM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2164},"outputId":"9d193aac-17a0-435b-dcc4-4745e5fca0af","executionInfo":{"status":"ok","timestamp":1551026718385,"user_tz":-330,"elapsed":690146,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["model.fit(X_train, Y_train, \n","          validation_data=(X_test, Y_test), \n","          epochs=60,\n","          batch_size=32)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/60\n","60000/60000 [==============================] - 11s 178us/sample - loss: 1.7523 - acc: 0.3735 - val_loss: 1.7335 - val_acc: 0.4105\n","Epoch 2/60\n","60000/60000 [==============================] - 11s 187us/sample - loss: 1.6150 - acc: 0.4155 - val_loss: 1.7758 - val_acc: 0.4151\n","Epoch 3/60\n","60000/60000 [==============================] - 11s 187us/sample - loss: 1.5625 - acc: 0.4352 - val_loss: 1.8079 - val_acc: 0.4333\n","Epoch 4/60\n","60000/60000 [==============================] - 12s 197us/sample - loss: 1.5269 - acc: 0.4449 - val_loss: 1.8834 - val_acc: 0.4297\n","Epoch 5/60\n","60000/60000 [==============================] - 12s 198us/sample - loss: 1.5008 - acc: 0.4530 - val_loss: 1.9551 - val_acc: 0.4220\n","Epoch 6/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.4808 - acc: 0.4581 - val_loss: 1.9372 - val_acc: 0.4297\n","Epoch 7/60\n","60000/60000 [==============================] - 12s 202us/sample - loss: 1.4634 - acc: 0.4667 - val_loss: 2.0435 - val_acc: 0.4172\n","Epoch 8/60\n","60000/60000 [==============================] - 12s 199us/sample - loss: 1.4513 - acc: 0.4719 - val_loss: 2.1070 - val_acc: 0.4225\n","Epoch 9/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.4455 - acc: 0.4766 - val_loss: 2.1404 - val_acc: 0.4142\n","Epoch 10/60\n","60000/60000 [==============================] - 12s 197us/sample - loss: 1.4391 - acc: 0.4756 - val_loss: 2.1152 - val_acc: 0.4260\n","Epoch 11/60\n","60000/60000 [==============================] - 12s 198us/sample - loss: 1.4233 - acc: 0.4810 - val_loss: 2.1958 - val_acc: 0.4162\n","Epoch 12/60\n","60000/60000 [==============================] - 12s 198us/sample - loss: 1.4162 - acc: 0.4847 - val_loss: 2.1746 - val_acc: 0.4219\n","Epoch 13/60\n","60000/60000 [==============================] - 12s 197us/sample - loss: 1.4116 - acc: 0.4882 - val_loss: 2.2341 - val_acc: 0.4280\n","Epoch 14/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.4057 - acc: 0.4922 - val_loss: 2.2192 - val_acc: 0.4156\n","Epoch 15/60\n","60000/60000 [==============================] - 12s 196us/sample - loss: 1.4020 - acc: 0.4927 - val_loss: 2.3221 - val_acc: 0.4154\n","Epoch 16/60\n","60000/60000 [==============================] - 11s 189us/sample - loss: 1.3963 - acc: 0.4947 - val_loss: 2.3072 - val_acc: 0.4132\n","Epoch 17/60\n","60000/60000 [==============================] - 12s 194us/sample - loss: 1.3914 - acc: 0.4946 - val_loss: 2.3683 - val_acc: 0.4148\n","Epoch 18/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3919 - acc: 0.4948 - val_loss: 2.3622 - val_acc: 0.4134\n","Epoch 19/60\n","60000/60000 [==============================] - 12s 192us/sample - loss: 1.3853 - acc: 0.4987 - val_loss: 2.3817 - val_acc: 0.4158\n","Epoch 20/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3817 - acc: 0.4991 - val_loss: 2.4163 - val_acc: 0.4171\n","Epoch 21/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3829 - acc: 0.5004 - val_loss: 2.4191 - val_acc: 0.4134\n","Epoch 22/60\n","60000/60000 [==============================] - 12s 196us/sample - loss: 1.3815 - acc: 0.5013 - val_loss: 2.3871 - val_acc: 0.4153\n","Epoch 23/60\n","60000/60000 [==============================] - 12s 192us/sample - loss: 1.3791 - acc: 0.5026 - val_loss: 2.4786 - val_acc: 0.4185\n","Epoch 24/60\n","60000/60000 [==============================] - 12s 201us/sample - loss: 1.3737 - acc: 0.5016 - val_loss: 2.5015 - val_acc: 0.4170\n","Epoch 25/60\n","60000/60000 [==============================] - 11s 178us/sample - loss: 1.3703 - acc: 0.5031 - val_loss: 2.4336 - val_acc: 0.4224\n","Epoch 26/60\n","60000/60000 [==============================] - 10s 173us/sample - loss: 1.3761 - acc: 0.5034 - val_loss: 2.6885 - val_acc: 0.4103\n","Epoch 27/60\n","60000/60000 [==============================] - 10s 173us/sample - loss: 1.3704 - acc: 0.5063 - val_loss: 2.5889 - val_acc: 0.4097\n","Epoch 28/60\n","60000/60000 [==============================] - 11s 186us/sample - loss: 1.3775 - acc: 0.5023 - val_loss: 2.5337 - val_acc: 0.4022\n","Epoch 29/60\n","60000/60000 [==============================] - 10s 173us/sample - loss: 1.3808 - acc: 0.5030 - val_loss: 2.5574 - val_acc: 0.4147\n","Epoch 30/60\n","60000/60000 [==============================] - 10s 173us/sample - loss: 1.3723 - acc: 0.5040 - val_loss: 2.5604 - val_acc: 0.4081\n","Epoch 31/60\n","60000/60000 [==============================] - 10s 174us/sample - loss: 1.3702 - acc: 0.5073 - val_loss: 2.5527 - val_acc: 0.4017\n","Epoch 32/60\n","60000/60000 [==============================] - 11s 175us/sample - loss: 1.3685 - acc: 0.5077 - val_loss: 2.6853 - val_acc: 0.4073\n","Epoch 33/60\n","60000/60000 [==============================] - 11s 191us/sample - loss: 1.3752 - acc: 0.5049 - val_loss: 2.6412 - val_acc: 0.4111\n","Epoch 34/60\n","60000/60000 [==============================] - 11s 178us/sample - loss: 1.3685 - acc: 0.5074 - val_loss: 2.7011 - val_acc: 0.4049\n","Epoch 35/60\n","60000/60000 [==============================] - 11s 175us/sample - loss: 1.3741 - acc: 0.5056 - val_loss: 2.6799 - val_acc: 0.4133\n","Epoch 36/60\n","60000/60000 [==============================] - 11s 176us/sample - loss: 1.3717 - acc: 0.5078 - val_loss: 2.6634 - val_acc: 0.4131\n","Epoch 37/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3665 - acc: 0.5085 - val_loss: 2.6370 - val_acc: 0.4171\n","Epoch 38/60\n","60000/60000 [==============================] - 12s 194us/sample - loss: 1.3631 - acc: 0.5091 - val_loss: 2.7884 - val_acc: 0.4034\n","Epoch 39/60\n","60000/60000 [==============================] - 12s 198us/sample - loss: 1.3671 - acc: 0.5071 - val_loss: 2.5774 - val_acc: 0.4005\n","Epoch 40/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3670 - acc: 0.5107 - val_loss: 2.6314 - val_acc: 0.4087\n","Epoch 41/60\n","60000/60000 [==============================] - 12s 194us/sample - loss: 1.3619 - acc: 0.5105 - val_loss: 2.7559 - val_acc: 0.4122\n","Epoch 42/60\n","60000/60000 [==============================] - 12s 192us/sample - loss: 1.3650 - acc: 0.5109 - val_loss: 2.6884 - val_acc: 0.3966\n","Epoch 43/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3727 - acc: 0.5076 - val_loss: 2.7062 - val_acc: 0.4091\n","Epoch 44/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3725 - acc: 0.5067 - val_loss: 2.6046 - val_acc: 0.3940\n","Epoch 45/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3654 - acc: 0.5084 - val_loss: 2.6347 - val_acc: 0.4164\n","Epoch 46/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3673 - acc: 0.5089 - val_loss: 2.6424 - val_acc: 0.4137\n","Epoch 47/60\n","60000/60000 [==============================] - 12s 194us/sample - loss: 1.3829 - acc: 0.5082 - val_loss: 2.6858 - val_acc: 0.4015\n","Epoch 48/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3899 - acc: 0.5045 - val_loss: 2.7724 - val_acc: 0.4010\n","Epoch 49/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3759 - acc: 0.5088 - val_loss: 2.8566 - val_acc: 0.4006\n","Epoch 50/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3775 - acc: 0.5065 - val_loss: 2.8597 - val_acc: 0.4035\n","Epoch 51/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3888 - acc: 0.5042 - val_loss: 2.8519 - val_acc: 0.4011\n","Epoch 52/60\n","60000/60000 [==============================] - 13s 214us/sample - loss: 1.3753 - acc: 0.5074 - val_loss: 2.7709 - val_acc: 0.4046\n","Epoch 53/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3769 - acc: 0.5088 - val_loss: 2.7368 - val_acc: 0.3979\n","Epoch 54/60\n","60000/60000 [==============================] - 12s 196us/sample - loss: 1.3873 - acc: 0.5059 - val_loss: 2.8306 - val_acc: 0.4063\n","Epoch 55/60\n","60000/60000 [==============================] - 13s 209us/sample - loss: 1.3788 - acc: 0.5069 - val_loss: 2.7044 - val_acc: 0.4070\n","Epoch 56/60\n","60000/60000 [==============================] - 12s 195us/sample - loss: 1.3744 - acc: 0.5095 - val_loss: 2.7768 - val_acc: 0.4028\n","Epoch 57/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3792 - acc: 0.5068 - val_loss: 2.7480 - val_acc: 0.4040\n","Epoch 58/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3742 - acc: 0.5102 - val_loss: 2.7769 - val_acc: 0.4014\n","Epoch 59/60\n","60000/60000 [==============================] - 12s 193us/sample - loss: 1.3937 - acc: 0.5043 - val_loss: 2.8255 - val_acc: 0.3948\n","Epoch 60/60\n","60000/60000 [==============================] - 12s 194us/sample - loss: 1.3780 - acc: 0.5092 - val_loss: 2.7986 - val_acc: 0.4008\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa609094290>"]},"metadata":{"tags":[]},"execution_count":57}]},{"metadata":{"id":"zjMXlgwCaBAA","colab_type":"code","colab":{}},"cell_type":"code","source":["#Initialize Sequential model\n","model1 = tf.keras.models.Sequential()\n","\n","#Reshape data from 2D to 1D -> 28x28 to 784\n","model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","#Normalize the data\n","model1.add(tf.keras.layers.BatchNormalization())\n","\n","# Fully Connected Layer\n","model1.add(tf.keras.layers.Dense(200))\n","model1.add(tf.keras.layers.Activation('relu'))\n","\n","# Fully Connected Layer\n","model1.add(tf.keras.layers.Dense(100))\n","model1.add(tf.keras.layers.Activation('relu'))\n","\n","# Dropout\n","model1.add(tf.keras.layers.Dropout(0.25))\n","\n","\n","# Prediction Layer\n","model1.add(tf.keras.layers.Dense(10))\n","model1.add(tf.keras.layers.Activation('softmax'))\n","\n","adam_optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","\n","#Comile the model\n","model1.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UddX08-Kaxi8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1108},"outputId":"74243dc7-e579-4875-9af5-af44ad3ba80f","executionInfo":{"status":"ok","timestamp":1551027308027,"user_tz":-330,"elapsed":214694,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["model.fit(X_train, Y_train, \n","          validation_data=(X_test, Y_test), \n","          epochs=30,\n","          batch_size=60)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/30\n","60000/60000 [==============================] - 7s 123us/sample - loss: 1.3110 - acc: 0.5298 - val_loss: 2.4308 - val_acc: 0.4137\n","Epoch 2/30\n","60000/60000 [==============================] - 7s 122us/sample - loss: 1.2812 - acc: 0.5390 - val_loss: 2.5400 - val_acc: 0.4199\n","Epoch 3/30\n","60000/60000 [==============================] - 7s 121us/sample - loss: 1.2679 - acc: 0.5411 - val_loss: 2.5330 - val_acc: 0.4182\n","Epoch 4/30\n","60000/60000 [==============================] - 7s 122us/sample - loss: 1.2635 - acc: 0.5425 - val_loss: 2.5586 - val_acc: 0.4171\n","Epoch 5/30\n","60000/60000 [==============================] - 7s 122us/sample - loss: 1.2592 - acc: 0.5429 - val_loss: 2.6102 - val_acc: 0.4198\n","Epoch 6/30\n","60000/60000 [==============================] - 7s 121us/sample - loss: 1.2529 - acc: 0.5469 - val_loss: 2.5395 - val_acc: 0.4160\n","Epoch 7/30\n","60000/60000 [==============================] - 7s 122us/sample - loss: 1.2484 - acc: 0.5483 - val_loss: 2.5525 - val_acc: 0.4207\n","Epoch 8/30\n","60000/60000 [==============================] - 7s 122us/sample - loss: 1.2504 - acc: 0.5454 - val_loss: 2.5700 - val_acc: 0.4198\n","Epoch 9/30\n","60000/60000 [==============================] - 7s 120us/sample - loss: 1.2427 - acc: 0.5498 - val_loss: 2.5856 - val_acc: 0.4210\n","Epoch 10/30\n","60000/60000 [==============================] - 7s 120us/sample - loss: 1.2409 - acc: 0.5487 - val_loss: 2.6224 - val_acc: 0.4239\n","Epoch 11/30\n","60000/60000 [==============================] - 7s 118us/sample - loss: 1.2367 - acc: 0.5497 - val_loss: 2.6150 - val_acc: 0.4138\n","Epoch 12/30\n","60000/60000 [==============================] - 7s 119us/sample - loss: 1.2322 - acc: 0.5534 - val_loss: 2.6194 - val_acc: 0.4147\n","Epoch 13/30\n","60000/60000 [==============================] - 7s 117us/sample - loss: 1.2378 - acc: 0.5528 - val_loss: 2.6020 - val_acc: 0.4295\n","Epoch 14/30\n","60000/60000 [==============================] - 7s 120us/sample - loss: 1.2342 - acc: 0.5502 - val_loss: 2.6467 - val_acc: 0.4164\n","Epoch 15/30\n","60000/60000 [==============================] - 7s 115us/sample - loss: 1.2308 - acc: 0.5538 - val_loss: 2.6827 - val_acc: 0.4217\n","Epoch 16/30\n","60000/60000 [==============================] - 7s 114us/sample - loss: 1.2282 - acc: 0.5513 - val_loss: 2.6645 - val_acc: 0.4140\n","Epoch 17/30\n","60000/60000 [==============================] - 7s 113us/sample - loss: 1.2324 - acc: 0.5535 - val_loss: 2.6669 - val_acc: 0.4210\n","Epoch 18/30\n","60000/60000 [==============================] - 7s 120us/sample - loss: 1.2252 - acc: 0.5521 - val_loss: 2.7283 - val_acc: 0.4174\n","Epoch 19/30\n","60000/60000 [==============================] - 7s 114us/sample - loss: 1.2268 - acc: 0.5539 - val_loss: 2.6686 - val_acc: 0.4133\n","Epoch 20/30\n","60000/60000 [==============================] - 7s 118us/sample - loss: 1.2301 - acc: 0.5532 - val_loss: 2.6571 - val_acc: 0.4209\n","Epoch 21/30\n","60000/60000 [==============================] - 8s 125us/sample - loss: 1.2287 - acc: 0.5536 - val_loss: 2.6202 - val_acc: 0.4187\n","Epoch 22/30\n","60000/60000 [==============================] - 6s 108us/sample - loss: 1.2242 - acc: 0.5566 - val_loss: 2.6709 - val_acc: 0.4192\n","Epoch 23/30\n","60000/60000 [==============================] - 7s 114us/sample - loss: 1.2251 - acc: 0.5579 - val_loss: 2.6889 - val_acc: 0.4116\n","Epoch 24/30\n","60000/60000 [==============================] - 7s 121us/sample - loss: 1.2270 - acc: 0.5550 - val_loss: 2.6704 - val_acc: 0.4178\n","Epoch 25/30\n","60000/60000 [==============================] - 8s 129us/sample - loss: 1.2277 - acc: 0.5530 - val_loss: 2.6862 - val_acc: 0.4223\n","Epoch 26/30\n","60000/60000 [==============================] - 7s 110us/sample - loss: 1.2183 - acc: 0.5582 - val_loss: 2.6945 - val_acc: 0.4155\n","Epoch 27/30\n","60000/60000 [==============================] - 7s 111us/sample - loss: 1.2180 - acc: 0.5543 - val_loss: 2.7468 - val_acc: 0.4149\n","Epoch 28/30\n","60000/60000 [==============================] - 7s 117us/sample - loss: 1.2278 - acc: 0.5559 - val_loss: 2.6708 - val_acc: 0.4204\n","Epoch 29/30\n","60000/60000 [==============================] - 7s 119us/sample - loss: 1.2196 - acc: 0.5574 - val_loss: 2.7516 - val_acc: 0.4133\n","Epoch 30/30\n","60000/60000 [==============================] - 7s 121us/sample - loss: 1.2229 - acc: 0.5544 - val_loss: 2.7146 - val_acc: 0.4179\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa6084c80d0>"]},"metadata":{"tags":[]},"execution_count":60}]},{"metadata":{"id":"vJl2GM7QQvs7","colab_type":"text"},"cell_type":"markdown","source":["## Word Embeddings in Python with Gensim"]},{"metadata":{"id":"9QoSmK_yQydL","colab_type":"text"},"cell_type":"markdown","source":["In this, you will practice how to train and load word embedding models for natural language processing applications in Python using Gensim.\n"]},{"metadata":{"id":"lqHUk1kBQ2Pl","colab_type":"text"},"cell_type":"markdown","source":["1. How to train your own word2vec word embedding model on text data.\n","2. How to visualize a trained word embedding model using Principal Component Analysis.\n","3. How to load pre-trained word2vec word embedding models."]},{"metadata":{"id":"x3EEkH5mQ6F0","colab_type":"text"},"cell_type":"markdown","source":["### Run the below two commands to install gensim and the wiki dataset"]},{"metadata":{"id":"Z_dPUh8YQ6Yi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"cd2f9894-caef-4d76-bdf3-0939b2d73613","executionInfo":{"status":"ok","timestamp":1551027327444,"user_tz":-330,"elapsed":8898,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["!pip install --upgrade gensim --user"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Collecting gensim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/1e/1efc81ea344ea2a22e954b1b4471b3d2d95b3b3fb156ba909e8bda67ed89/gensim-3.7.1-cp27-cp27mu-manylinux1_x86_64.whl (24.2MB)\n","\u001b[K    100% |████████████████████████████████| 24.2MB 940kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: smart-open>=1.7.0 in /usr/local/lib/python2.7/dist-packages (from gensim) (1.8.0)\n","Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python2.7/dist-packages (from gensim) (1.11.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python2.7/dist-packages (from gensim) (1.1.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python2.7/dist-packages (from gensim) (1.14.6)\n","Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python2.7/dist-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n","Requirement already satisfied, skipping upgrade: bz2file in /usr/local/lib/python2.7/dist-packages (from smart-open>=1.7.0->gensim) (0.98)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python2.7/dist-packages (from smart-open>=1.7.0->gensim) (2.18.4)\n","Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python2.7/dist-packages (from smart-open>=1.7.0->gensim) (1.9.95)\n","Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.7.0->gensim) (2.6)\n","Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.7.0->gensim) (1.22)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n","Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.95 in /usr/local/lib/python2.7/dist-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.95)\n","Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python2.7/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.3)\n","Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.0)\n","Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python2.7/dist-packages (from botocore<1.13.0,>=1.12.95->boto3->smart-open>=1.7.0->gensim) (0.14)\n","Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python2.7/dist-packages (from botocore<1.13.0,>=1.12.95->boto3->smart-open>=1.7.0->gensim) (2.5.3)\n","Requirement already satisfied, skipping upgrade: futures<4.0.0,>=2.2.0; python_version == \"2.6\" or python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from s3transfer<0.3.0,>=0.2.0->boto3->smart-open>=1.7.0->gensim) (3.2.0)\n","Installing collected packages: gensim\n","Successfully installed gensim-3.7.1\n"],"name":"stdout"}]},{"metadata":{"id":"-9-xPiuTQ-nD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"507205bb-42f9-4f7a-d802-6e754ce4738f","executionInfo":{"status":"ok","timestamp":1551027332987,"user_tz":-330,"elapsed":6754,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["!pip install wikipedia --user"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Collecting wikipedia\n","  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python2.7/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from wikipedia) (2.18.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2018.11.29)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"],"name":"stdout"}]},{"metadata":{"id":"Te2mI1FHQ_I1","colab_type":"text"},"cell_type":"markdown","source":["### Import gensim"]},{"metadata":{"id":"qQQwRUJ0RAlJ","colab_type":"code","colab":{}},"cell_type":"code","source":["import gensim"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CCnGsW4adLdg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"0b8d4afd-919f-47b0-81fc-47240ee636b7","executionInfo":{"status":"ok","timestamp":1551027735168,"user_tz":-330,"elapsed":4706,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["!sudo pip install wikipedia --user"],"execution_count":69,"outputs":[{"output_type":"stream","text":["\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n","Requirement already satisfied: wikipedia in /root/.local/lib/python2.7/site-packages (1.4.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python2.7/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from wikipedia) (2.18.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2018.11.29)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n"],"name":"stdout"}]},{"metadata":{"id":"5dXgBNlORBGP","colab_type":"text"},"cell_type":"markdown","source":["### Obtain Text"]},{"metadata":{"id":"xdnvuDLCRDO4","colab_type":"text"},"cell_type":"markdown","source":["Import search and page functions from wikipedia module\n","search(/key word/): search function takes keyword as argument and gives top 10 article titles matching the given keyword.\n","\n","page(/title of article/): page function takes page title as argument and gives content in the output."]},{"metadata":{"id":"ZUXD4HKDcoD0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"42cb0fd9-59eb-4fe4-c6d8-0a090e8cfd0e","executionInfo":{"status":"ok","timestamp":1551027910420,"user_tz":-330,"elapsed":4532,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["!sudo apt install wikipedia"],"execution_count":74,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","E: Unable to locate package wikipedia\n"],"name":"stdout"}]},{"metadata":{"id":"VgB7SX-TRHNT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":378},"outputId":"fe46ef48-fc0f-4091-b3d2-d61513a76a8b","executionInfo":{"status":"error","timestamp":1551027862257,"user_tz":-330,"elapsed":813,"user":{"displayName":"chenthur murugan","photoUrl":"","userId":"10011307527226996772"}}},"cell_type":"code","source":["## Usage: \n","\n","from wikipedia import search, page\n","'''titles = search(\"Indian Premier League\")\n","wikipage = page(titles[0])\n","print wikipage.content'''"],"execution_count":71,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-71-3ee96296c693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwikipedia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m '''titles = search(\"Indian Premier League\")\n\u001b[1;32m      4\u001b[0m \u001b[0mwikipage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print wikipage.content'''\n","\u001b[0;31mImportError\u001b[0m: No module named wikipedia","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"q54h4vNaRJXe","colab_type":"text"},"cell_type":"markdown","source":["### Print the top 10 titles for the keyword `Machine Learning`"]},{"metadata":{"id":"yuyLmsnsRK6f","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"a3faXGqLRQx1","colab_type":"text"},"cell_type":"markdown","source":["### Get the content from the first title from the above obtained 10 titles."]},{"metadata":{"id":"HOqiYzrqRQ-M","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"C8ugHUzSRTFH","colab_type":"text"},"cell_type":"markdown","source":["### Create a list with name `documents` and append all the words in the 10 pages' content using the above 10 titles."]},{"metadata":{"id":"nBKXHtfCRTZw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"eyo1zvzERVgG","colab_type":"text"},"cell_type":"markdown","source":["### Build the gensim model for word2vec with by considering all the words with frequency >=1 with embedding size=50"]},{"metadata":{"id":"hMkxm5eHRVts","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FyLV4F6uRYZx","colab_type":"text"},"cell_type":"markdown","source":["### Exploring the model"]},{"metadata":{"id":"6iuSUoJERYhc","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"XxUuShBTRaYH","colab_type":"text"},"cell_type":"markdown","source":["#### Check how many words in the model"]},{"metadata":{"id":"S4lMhzWlRamw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KshrfDklReIl","colab_type":"text"},"cell_type":"markdown","source":["### Get an embedding for word `SVM`"]},{"metadata":{"id":"YiwT1OjARg6e","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"7COLA1LzRhTj","colab_type":"text"},"cell_type":"markdown","source":["### Finding most similar words for word `learning`"]},{"metadata":{"id":"tEsMKWY6Ri3n","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"K8QjNuDKRlvt","colab_type":"text"},"cell_type":"markdown","source":["### Find the word which is not like others from `machine, svm, ball, learning`"]},{"metadata":{"id":"oBudwDHtRl3u","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"cjNQ0yMNRn6D","colab_type":"text"},"cell_type":"markdown","source":["### Save the model with name `word2vec-wiki-10`"]},{"metadata":{"id":"bynMebY5RoLn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"cDeem0T5RqTn","colab_type":"text"},"cell_type":"markdown","source":["### Load the model `word2vec-wiki-10`"]},{"metadata":{"id":"VJJk04KfRqen","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}